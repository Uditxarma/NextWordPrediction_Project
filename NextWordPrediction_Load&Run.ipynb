{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmyLI3Ni5puPRutBnB1dp8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uditxarma/NextWordPrediction_Project/blob/main/NextWordPrediction_Load%26Run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install h5py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAB6l4_IyOTs",
        "outputId": "85989177-1f10-4ac6-fd9c-b94c9caf5aa6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.5 in /usr/local/lib/python3.8/dist-packages (from h5py) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "m7vU4P2kvVsS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EesbVfumvgJA",
        "outputId": "5e87ebf9-8567-4d35-d289-9d5c8d3d1c09"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(\"/content/drive/MyDrive/Next Word Prediction/DataWork.txt\",\"r\",encoding =\"utf8\")  "
      ],
      "metadata": {
        "id": "VuTtIOaKw-Ux"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines=[] \n",
        "for i in file:\n",
        "  lines.append(i)\n",
        "data=\"\" \n",
        "for i in lines:\n",
        "  data=' '.join(lines) \n",
        "  data=data.replace('\\n','').replace('\\r','').replace('\\ufeff','').replace('\"','').replace('.','').replace(',','').replace('!','').replace('@','').replace('#','').replace('$','').replace('%','').replace('^','').replace('&','').replace('*','').replace('(','').replace(')','').replace('+','').replace('/','').replace('<','').replace('>','').replace('?','').replace('{','').replace('}','').replace('[','').replace(']','').replace(';','').replace(':','').replace('|','')\n",
        "data=data.split() \n",
        "data=' '.join(data) \n",
        "data[:500]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "iHeh4upoxCum",
        "outputId": "e1b759ce-696e-45ef-a9c5-d7fd36070a3b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Project Gutenberg eBook of Persuasion by Jane Austen This eBook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever You may copy it give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at wwwgutenbergorg If you are not located in the United States you will have to check the laws of the country where you are located before using this eBook Title P'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnTJnD_0xHvR",
        "outputId": "04707e62-d85d-471b-94a2-26ebd0f7a08f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "469882"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer() \n",
        "tokenizer.fit_on_texts([data])\n",
        "pickle.dump(tokenizer,open('token.pk2','wb'))\n",
        "sequence_data = tokenizer.texts_to_sequences([data])[0] \n",
        "sequence_data[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-l-8f9AxLLG",
        "outputId": "71702449-613a-48d3-b84f-cc8da55c6248"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 134, 136, 706, 4, 807, 29, 2123, 2124, 45, 706, 35, 18, 1, 267]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sequence_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV9UFr7X1yz-",
        "outputId": "1fdfa949-89ff-452f-e0a0-e8fc43d954c1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86730"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index)+1 \n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rWUpR1xxZAQ",
        "outputId": "b664efc1-ff12-4588-c368-34fcff146a54"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = [] \n",
        "for i in range(3,len(sequence_data)):\n",
        "   words = sequence_data[i-3:i+1]     \n",
        "   sequences.append(words)\n",
        "print(\"The Length of sequence are: \",len(sequences)) \n",
        "sequences =np.array(sequences)\n",
        "sequences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJppOFu0xdXr",
        "outputId": "714092e6-2f5c-41f2-ceb6-69f64d6e888c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Length of sequence are:  86727\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   1,  134,  136,  706],\n",
              "       [ 134,  136,  706,    4],\n",
              "       [ 136,  706,    4,  807],\n",
              "       [ 706,    4,  807,   29],\n",
              "       [   4,  807,   29, 2123],\n",
              "       [ 807,   29, 2123, 2124],\n",
              "       [  29, 2123, 2124,   45],\n",
              "       [2123, 2124,   45,  706],\n",
              "       [2124,   45,  706,   35],\n",
              "       [  45,  706,   35,   18]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=[] \n",
        "Y=[] \n",
        "for i in sequences:     \n",
        "  X.append(i[0:3])\n",
        "  Y.append(i[3])\n",
        "X=np.array(X) \n",
        "Y=np.array(Y)\n",
        "print(\"Data: \",X[:10]) \n",
        "print(\"Response: \",Y[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVgkPazPxi50",
        "outputId": "572f0422-8194-45ef-d2a1-b3ee31db7a92"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data:  [[   1  134  136]\n",
            " [ 134  136  706]\n",
            " [ 136  706    4]\n",
            " [ 706    4  807]\n",
            " [   4  807   29]\n",
            " [ 807   29 2123]\n",
            " [  29 2123 2124]\n",
            " [2123 2124   45]\n",
            " [2124   45  706]\n",
            " [  45  706   35]]\n",
            "Response:  [ 706    4  807   29 2123 2124   45  706   35   18]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 10, input_length=3)) \n",
        "model.add(LSTM(1000,return_sequences=True)) \n",
        "model.add(LSTM(1000)) \n",
        "model.add(Dense(1000,activation='relu')) \n",
        "model.add(Dense(vocab_size, activation ='softmax'))"
      ],
      "metadata": {
        "id": "YcIzli1mxrHW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = tf.keras.models.load_model('/content/drive/MyDrive/Next Word Prediction/next_word.h5')\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l4ITc6WxwkL",
        "outputId": "755f6158-69fe-4114-999e-6e44bb668442"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 3, 10)             68880     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 3, 1000)           4044000   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 1000)              8004000   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1000)              1001000   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6888)              6894888   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,012,768\n",
            "Trainable params: 20,012,768\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model = load_model('/content/drive/MyDrive/Next Word Prediction/next_word.h5')\n",
        "tokenizer = pickle.load(open('token.pk2', 'rb'))\n",
        "\n",
        "def Predict_Next_Words(model, tokenizer, text):\n",
        "\n",
        "  sequence = tokenizer.texts_to_sequences([text])\n",
        "  sequence = np.array(sequence)\n",
        "  preds = np.argmax(model.predict(sequence))\n",
        "  predicted_word = \"\"\n",
        "  \n",
        "  for key, value in tokenizer.word_index.items():\n",
        "      if value == preds:\n",
        "          predicted_word = key\n",
        "          break\n",
        "  \n",
        "  print(predicted_word)\n",
        "  return predicted_word"
      ],
      "metadata": {
        "id": "sQprCH0sxzya"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while(True):\n",
        "  text = input(\"Enter your line: \")\n",
        "  \n",
        "  if text == \"0\":\n",
        "      print(\"Execution completed.....\")\n",
        "      break\n",
        "  \n",
        "  else:\n",
        "      try:\n",
        "          text = text.split(\" \")\n",
        "          text = text[-3:]\n",
        "          print(text)\n",
        "        \n",
        "          Predict_Next_Words(model, tokenizer, text)\n",
        "          \n",
        "      except Exception as e:\n",
        "        print(\"Error occurred: \",e)\n",
        "        continue\n",
        "        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3NeMe-kxnQw",
        "outputId": "d2c8521d-097e-4064-b99d-2e5f988393c1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your line: He considered the\n",
            "['He', 'considered', 'the']\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "blessing\n",
            "Enter your line: had attempted no\n",
            "['had', 'attempted', 'no']\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "apology\n",
            "Enter your line: 0\n",
            "Execution completed.....\n"
          ]
        }
      ]
    }
  ]
}